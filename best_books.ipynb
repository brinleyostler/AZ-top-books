{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SELENIUM - XPath Webscraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E-book Scraping:\n",
    "Here is the link for the top 1,000 E-books at the Greater Phoenix Digital Library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_e = 'https://phoenix.overdrive.com/collection/25972'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the driver to access the website:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use Selenium to utilize the Chrome web driver to access and scrape the data using their XPaths.\n",
    "\n",
    "Here is the code to access the information for just the first book:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#container_e = driver.find_element(By.XPATH, \".//section[contains(@id, 'search')]\")\n",
    "#all_books = container_e.find_elements(By.XPATH, \".//li[contains(@class, 'js-titleCard Item')]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_books[0].find_element(By.XPATH, \".//h3[contains(@class, 'title-name')]\").text  # book title\n",
    "#all_books[0].find_element(By.XPATH, \".//p[contains(@class, 'title-author')]\").text.replace('by ', '')  # author\n",
    "#all_books[0].find_element(By.XPATH, \".//div[contains(@class, 'title-header-bar')]\").text  # availability\n",
    "#all_books[0].find_element(By.XPATH, \".//span[contains(@class, 'title-format-badge')]\").text  # book format\n",
    "#all_books[0].find_element(By.XPATH, \".//div[contains(@class, 'TitleInfo')]/h3/a\").get_attribute('href')  # book link\n",
    "\n",
    "#pagination = driver.find_element(By.XPATH, './/ul[contains(@class, \"Pagination-itemsContainer\")]')\n",
    "#pagination.find_elements(By.XPATH, './/a[contains(@class, \"Pagination-item\")]')[-2].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use that same code to access the information for all the books.\n",
    "\n",
    "*Since the list is very long and on 42 different sites, we will limit our scraping to just the first 10 pages (top 240 e-books).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_titles = []\n",
    "book_authors = []\n",
    "book_availability = []\n",
    "book_formats = []\n",
    "book_links = []\n",
    "book_ranks = []\n",
    "\n",
    "current_page = 1\n",
    "last_page = 10  # we will only scrape the first 10 pages (240 elements total)\n",
    "rank = 1\n",
    "\n",
    "driver.get(url_e)\n",
    "\n",
    "while current_page <= last_page:\n",
    "    container_e = driver.find_element(By.XPATH, \".//section[contains(@id, 'search')]\")\n",
    "    all_ebooks = container_e.find_elements(By.XPATH, \".//li[contains(@class, 'js-titleCard Item')]\")\n",
    "\n",
    "    for book in all_ebooks:\n",
    "        title = book.find_element(By.XPATH, \".//h3[contains(@class, 'title-name')]\").text\n",
    "        book_titles.append(title)\n",
    "\n",
    "        author = book.find_element(By.XPATH, \".//p[contains(@class, 'title-author')]\").text.replace('by ', '')\n",
    "        book_authors.append(author)\n",
    "\n",
    "        availability = book.find_element(By.XPATH, \".//div[contains(@class, 'title-header-bar')]\").text\n",
    "        book_availability.append(availability)\n",
    "\n",
    "        format = book.find_element(By.XPATH, \".//span[contains(@class, 'title-format-badge')]\").text\n",
    "        book_formats.append(format)\n",
    "\n",
    "        link = book.find_element(By.XPATH, \".//div[contains(@class, 'TitleInfo')]/h3/a\").get_attribute('href')\n",
    "        book_links.append(link)\n",
    "\n",
    "        book_ranks.append(rank)\n",
    "        rank += 1\n",
    "\n",
    "    try:\n",
    "        next_button = driver.find_element(By.XPATH, './/a[contains(@class, \"Pagination-item\") and @aria-label=\"Next page\"]')\n",
    "        next_button.click()\n",
    "        current_page += 1\n",
    "        time.sleep(2)\n",
    "\n",
    "    except:\n",
    "        pass\n",
    " \n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "240"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_ranks[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Audiobook Scraping:\n",
    "Here is the link for the top 1,000 audiobooks on the Greater Phoenix Digital Library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()))\n",
    "\n",
    "url_a = 'https://phoenix.overdrive.com/collection/25978'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we want our database to be altogether, we will not declare new book lists. We will simply add on to our lists already defined in the ebook section. We will gather all the same information.\n",
    "\n",
    "Similarly, we will only scrape the first 10 pages, accessing the top 240 audiobooks and truncating them on our ebook list for a grand total of the top 480 books (there may be some overlap)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_page = 1  # redeclare this variable to reset to the first page of the new url\n",
    "last_page = 10  # we will only scrape the first 10 pages (240 elements total)\n",
    "rank = 1  # reset to 1\n",
    "\n",
    "driver.get(url_a)\n",
    "\n",
    "while current_page <= last_page:\n",
    "    container_a = driver.find_element(By.XPATH, \".//section[contains(@id, 'search')]\")\n",
    "    all_abooks = container_a.find_elements(By.XPATH, \".//li[contains(@class, 'js-titleCard Item')]\")\n",
    "\n",
    "    for book in all_abooks:\n",
    "        title = book.find_element(By.XPATH, \".//h3[contains(@class, 'title-name')]\").text\n",
    "        book_titles.append(title)\n",
    "\n",
    "        author = book.find_element(By.XPATH, \".//p[contains(@class, 'title-author')]\").text.replace('by ', '')\n",
    "        book_authors.append(author)\n",
    "\n",
    "        availability = book.find_element(By.XPATH, \".//div[contains(@class, 'title-header-bar')]\").text\n",
    "        book_availability.append(availability)\n",
    "\n",
    "        format = book.find_element(By.XPATH, \".//span[contains(@class, 'title-format-badge')]\").text\n",
    "        book_formats.append(format)\n",
    "\n",
    "        link = book.find_element(By.XPATH, \".//div[contains(@class, 'TitleInfo')]/h3/a\").get_attribute('href')\n",
    "        book_links.append(link)\n",
    "\n",
    "        book_ranks.append(rank)\n",
    "        rank += 1\n",
    "\n",
    "    try:\n",
    "        next_button = driver.find_element(By.XPATH, './/a[contains(@class, \"Pagination-item\") and @aria-label=\"Next page\"]')\n",
    "        next_button.click()\n",
    "        current_page += 1\n",
    "        time.sleep(2)\n",
    "\n",
    "    except:\n",
    "        pass\n",
    " \n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "240"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_ranks[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing Individual Websites   \n",
    "Now that we have scraped our list of books with Selenium, we will continue scraping our data, now from each individual website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://phoenix.overdrive.com/media/9768977?cid=25972',\n",
       " 'https://phoenix.overdrive.com/media/8839068?cid=25972',\n",
       " 'https://phoenix.overdrive.com/media/5376582?cid=25972',\n",
       " 'https://phoenix.overdrive.com/media/2461050?cid=25972',\n",
       " 'https://phoenix.overdrive.com/media/10012377?cid=25972']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_links[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we'll be opening 480 individual sites, we want to now operate with a sleep timer in our for loop to sleep for two seconds after accessing each link.\n",
    "\n",
    "While this will take our code much longer to run, we want to follow good practice in web scraping and avoid crashing or overloading any website.\n",
    "\n",
    "*Depending on the speed of your computer and browser, the code will run for at least 960 seconds (16 minutes). Mine ran for about 20 minutes.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()))\n",
    "#driver.get(book_links[2])\n",
    "#container = driver.find_element(By.CLASS_NAME, 'title-header-container')\n",
    "\n",
    "# COPIES TOTAL\n",
    "#copies_x = container.find_element(By.XPATH, \".//span[contains(@class, 'availabilityText')]\").text\n",
    "#copies_y = re.sub(r' cop(y|ies) available', '', copies_x)  # removes the phrase\n",
    "#copies = int(re.sub(r'.* of ', '', copies_y))\n",
    "\n",
    "# STARS RATING\n",
    "#stars = container.find_element(By.XPATH, \".//div[contains(@class, 'StarRating')]\").get_attribute('data-global-rating')\n",
    "\n",
    "#driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_copies = []\n",
    "book_ratings = []\n",
    "\n",
    "count = 0\n",
    "\n",
    "driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()))  #, options=options\n",
    "\n",
    "for link in book_links:\n",
    "    count += 1\n",
    "    driver.get(link)\n",
    "    \n",
    "    time.sleep(2)\n",
    "    \n",
    "    container = driver.find_element(By.CLASS_NAME, 'title-header-container')\n",
    "\n",
    "    try:\n",
    "        copies_x = container.find_element(By.XPATH, \".//span[contains(@class, 'availabilityText')]\").text\n",
    "        copies_y = re.sub(r' cop(y|ies) available', '', copies_x)  # removes the phrase 'copies available'\n",
    "        copies = int(re.sub(r'.* of ', '', copies_y))  # keeps only the number of copies\n",
    "    except:\n",
    "        copies = None\n",
    "    book_copies.append(copies)\n",
    "\n",
    "    try:\n",
    "        rating_x = container.find_element(By.XPATH, \".//div[contains(@class, 'StarRating')]\").get_attribute('data-global-rating')\n",
    "        rating = float(rating_x)\n",
    "    except:\n",
    "        rating = None\n",
    "    book_ratings.append(rating)\n",
    "    \n",
    "    \n",
    "driver.quit()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "480"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(book_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(book_copies[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PANDAS DataFrame\n",
    "Now we will assemble the data we have just scraped into a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Format</th>\n",
       "      <th>Copies</th>\n",
       "      <th>Availability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The Women</td>\n",
       "      <td>Kristin Hannah</td>\n",
       "      <td>4.5</td>\n",
       "      <td>EBOOK</td>\n",
       "      <td>25.0</td>\n",
       "      <td>WAIT LIST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Desert Star</td>\n",
       "      <td>Michael Connelly</td>\n",
       "      <td>4.3</td>\n",
       "      <td>EBOOK</td>\n",
       "      <td>25.0</td>\n",
       "      <td>AVAILABLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Five Total Strangers</td>\n",
       "      <td>Natalie D. Richards</td>\n",
       "      <td>3.5</td>\n",
       "      <td>EBOOK</td>\n",
       "      <td>12.0</td>\n",
       "      <td>AVAILABLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>It Ends With Us</td>\n",
       "      <td>Colleen Hoover</td>\n",
       "      <td>4.3</td>\n",
       "      <td>EBOOK</td>\n",
       "      <td>15.0</td>\n",
       "      <td>WAIT LIST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Funny Story</td>\n",
       "      <td>Emily Henry</td>\n",
       "      <td>4.2</td>\n",
       "      <td>EBOOK</td>\n",
       "      <td>18.0</td>\n",
       "      <td>WAIT LIST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                 Title               Author  Rating Format  Copies  \\\n",
       "0     1             The Women       Kristin Hannah     4.5  EBOOK    25.0   \n",
       "1     2           Desert Star     Michael Connelly     4.3  EBOOK    25.0   \n",
       "2     3  Five Total Strangers  Natalie D. Richards     3.5  EBOOK    12.0   \n",
       "3     4       It Ends With Us       Colleen Hoover     4.3  EBOOK    15.0   \n",
       "4     5           Funny Story          Emily Henry     4.2  EBOOK    18.0   \n",
       "\n",
       "  Availability  \n",
       "0    WAIT LIST  \n",
       "1    AVAILABLE  \n",
       "2    AVAILABLE  \n",
       "3    WAIT LIST  \n",
       "4    WAIT LIST  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_books = pd.DataFrame({'Rank': book_ranks, 'Title': book_titles, 'Author': book_authors, 'Rating': book_ratings,\n",
    "                          'Format': book_formats, 'Copies': book_copies, 'Availability': book_availability})\n",
    "top_books.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataframe to a csv file\n",
    "top_books.to_csv('AZ_top_books.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "classes24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
